{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef4bc6b4-7795-4a32-9389-e0946ad0b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002875d8-162e-4e27-81bd-ca229e5b23fe",
   "metadata": {},
   "source": [
    "**Будем оптимизировать функцию MSE для линейной регрессии. MSE в матричном виде**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ead82ae-6ae3-4588-aa3c-172298e63481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X: np.array, y : np.array, w0: np.array, learning_rate: float, iterations: int, eps=1e-4):\n",
    "\n",
    "    '''Функция поиска минимума функции MSE в векторном виде с использованием классического градиентного спуска'''\n",
    "    m = X.shape[0] # кол-во объектов\n",
    "    if w0.shape[-1] != X.shape[-1] + 1:\n",
    "        return 'Неверно задана матрица весов w0. Проверьте количество признаков'\n",
    "    X = np.hstack((np.ones((m, 1)), X)) # добавляем константу для w0\n",
    "    params = w0\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        grad = X.T @ ((X @ params) - y) # X.T @ - вычисляет градиенты, ((X @ params) - y) - вычисляет ошибки по каждому объекту\n",
    "        update =  (2./m) * learning_rate * grad\n",
    "\n",
    "        if np.linalg.norm(update) < eps:\n",
    "            return params\n",
    "        params -= update\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c441a-05fa-41a4-a2b2-29c43e406d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(X: np.array, y : np.array, w0: np.array, learning_rate: float, iterations: int, batch=1, eps=1e-4):\n",
    "\n",
    "    '''Функция поиска минимума функции MSE в векторном виде с использованием модификации mini batch. \n",
    "        По умолчанию параметр batch = 1, то есть используется Стохастический градиентный спуск.'''\n",
    "    \n",
    "    m = X.shape[0] # кол-во объектов\n",
    "    if w0.shape[-1] != X.shape[-1] + 1:\n",
    "        return 'Неверно задана матрица весов w0. Проверьте количество признаков'\n",
    "    X = np.hstack((np.ones((m, 1)), X)) # добавляем константу для w0\n",
    "    params = w0\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        idxs = np.random.randint(0, m, batch)\n",
    "        X_mini, y_mini = X[idxs], y[idxs]\n",
    "        grad = X_mini.T @ ((X_mini @ params) - y_mini) # X.T @ - вычисляет градиенты, ((X @ params) - y) - вычисляет ошибки по каждому объекту\n",
    "        update =  (2./batch) * learning_rate * grad\n",
    "\n",
    "        if np.linalg.norm(update) < eps:\n",
    "            return params\n",
    "        params -= update\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d78ed124-a21a-4c53-be09-ceeed21c6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(X: np.array, y : np.array, w0: np.array, learning_rate: float, iterations: int, beta: int, Nesterov=False, eps=1e-4):\n",
    "\n",
    "    '''Функция поиска минимума функции MSE в векторном виде с использованием метода моментов'''\n",
    "    m = X.shape[0] # кол-во объектов\n",
    "    if w0.shape[-1] != X.shape[-1] + 1:\n",
    "        return 'Неверно задана матрица весов w0. Проверьте количество признаков'\n",
    "    X = np.hstack((np.ones((m, 1)), X)) # добавляем константу для w0\n",
    "    params = w0\n",
    "    h = 0\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        if Nesterov:\n",
    "            grad = X.T @ ((X @ (params - beta * h)) - y) # учитываем 'импульс'\n",
    "\n",
    "        else:\n",
    "            grad = X.T @ ((X @ params) - y)\n",
    "        h =  beta * h - (2./m) * learning_rate * grad\n",
    "        \n",
    "        if np.linalg.norm(h) < eps:\n",
    "            return params\n",
    "        params -= h\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "42bf69e0-c6d7-4d64-8569-4f48900d06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSprop(X: np.array, y : np.array, w0: np.array, iterations: int, learning_rate=0.01, beta=0.9, eps=1e-3):\n",
    "    '''Функция поиска минимума функции MSE в векторном виде с использованием метода Root Mean Squared propagation'''\n",
    "    m = X.shape[0] # кол-во объектов\n",
    "    if w0.shape[-1] != X.shape[-1] + 1:\n",
    "        return 'Неверно задана матрица весов w0. Проверьте количество признаков'\n",
    "    X = np.hstack((np.ones((m, 1)), X)) # добавляем константу для w0\n",
    "    params = w0\n",
    "    G = np.zeros_like(params)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        grad = X.T @ ((X @ params) - y)  \n",
    "        G = beta * G + (1 - beta) * grad ** 2  # Сглаживание квадратов градиента\n",
    "        update = (learning_rate / (np.sqrt(G) + eps)) * grad  # Обновление параметров\n",
    "\n",
    "        if np.linalg.norm(update) < eps:  \n",
    "            return params\n",
    "        \n",
    "        params -= update  \n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "55b1cb72-d320-4505-921e-cbf0fa24d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adam(X: np.array, y : np.array, w0: [np.array, list, tuple], iterations: int, learning_rate: float, beta_1: float, beta_2: float, eps=1e-3):\n",
    "    '''Функция для поиска минимума функции MSE в векторном виде с использоваением метода Adam'''\n",
    "    m = X.shape[0] # кол-во объектов\n",
    "    if w0.shape[-1] != X.shape[-1] + 1:\n",
    "        return 'Неверно задана матрица весов w0. Проверьте количество признаков'\n",
    "    X = np.hstack((np.ones((m, 1)), X)) # добавляем константу для w0\n",
    "    params = np.array(w0)\n",
    "    h = np.zeros_like(params)\n",
    "    G = np.zeros_like(params)\n",
    "    \n",
    "    for i in range(1, iterations+1):\n",
    "        grad = X.T @ ((X @ params) - y) \n",
    "        h = (beta_1 * h + (1 - beta_1) * grad) / (1 - beta_1)\n",
    "        G = (beta_2 * G + (1 - beta_2) * grad ** 2) / (1 - beta_2)  # Сглаживание квадратов градиента\n",
    "\n",
    "        # Коррекция смещенния для компенсации нулевой инициализации\n",
    "        h_t = h / (1 - beta_1 ** i)\n",
    "        G_t = G / (1 - beta_2 ** i)\n",
    "        update = (learning_rate / (np.sqrt(G_t) + eps)) * h_t # Обновление параметров\n",
    "\n",
    "        if np.linalg.norm(update) < eps:  \n",
    "            return params\n",
    "        \n",
    "        params -= update  \n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9c68d-2292-40c2-8094-fe48ead4e05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
